{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd920c94-bfa6-4fa2-92bd-f9bc06304a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchdiffeq import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5dcb1c-9856-4833-ba37-f47c1eeafa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a mixture of Gaussians\n",
    "def generate_mixture_of_gaussians(n_samples, n_components, dim, std=0.1):\n",
    "    np.random.seed(42)\n",
    "    centers = np.random.uniform(-1, 1, (n_components, dim))\n",
    "    samples = []\n",
    "    for _ in range(n_samples):\n",
    "        component = np.random.randint(0, n_components)\n",
    "        sample = np.random.normal(centers[component], std, dim)\n",
    "        samples.append(sample)\n",
    "    return np.array(samples), centers\n",
    "\n",
    "# Plotting function\n",
    "def plot_data(data, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(data[:, 0], data[:, 1], s=5, alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot images in a grid\n",
    "def plot_images_grid(images, title, n=10):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(n):\n",
    "        plt.subplot(2, n, i + 1)\n",
    "        plt.imshow((images[i].transpose(1, 2, 0) * 0.5 + 0.5).clip(0, 1))\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076eddbe-ddb4-441f-997f-4951755c3ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Real NVP Implementation for 2D Data ###\n",
    "class AffineCouplingLayer2D(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, mask):\n",
    "        super(AffineCouplingLayer2D, self).__init__()\n",
    "        self.mask = mask\n",
    "        self.scale_net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.translate_net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = self.mask.to(x.device)  # Ensure the mask is on the same device as x\n",
    "        x1 = x * mask\n",
    "        s = self.scale_net(x1) * (1 - mask)\n",
    "        t = self.translate_net(x1) * (1 - mask)\n",
    "        z = x1 + (1 - mask) * (x * torch.exp(s) + t)\n",
    "        log_det_jacobian = torch.sum((1 - mask) * s, dim=1)\n",
    "        return z, log_det_jacobian\n",
    "\n",
    "    def inverse(self, z):\n",
    "        mask = self.mask.to(z.device)  # Ensure the mask is on the same device as z\n",
    "        z1 = z * mask\n",
    "        s = self.scale_net(z1) * (1 - mask)\n",
    "        t = self.translate_net(z1) * (1 - mask)\n",
    "        x = z1 + (1 - mask) * (z - t) * torch.exp(-s)\n",
    "        return x\n",
    "\n",
    "# Define the Real NVP Model for 2D data\n",
    "class RealNVP2D(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_coupling_layers):\n",
    "        super(RealNVP2D, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_coupling_layers = n_coupling_layers\n",
    "\n",
    "        self.masks = []\n",
    "        for i in range(n_coupling_layers):\n",
    "            mask = torch.tensor([1 if j % 2 == 0 else 0 for j in range(input_dim)], dtype=torch.float32)\n",
    "            if i % 2 == 0:\n",
    "                mask = 1 - mask\n",
    "            self.masks.append(mask)\n",
    "\n",
    "        self.coupling_layers = nn.ModuleList([AffineCouplingLayer2D(input_dim, hidden_dim, self.masks[i])\n",
    "                                              for i in range(n_coupling_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        log_det_jacobian = 0\n",
    "        for layer in self.coupling_layers:\n",
    "            x, layer_log_det_jacobian = layer(x)\n",
    "            log_det_jacobian += layer_log_det_jacobian\n",
    "        return x, log_det_jacobian\n",
    "\n",
    "    def inverse(self, z):\n",
    "        for layer in reversed(self.coupling_layers):\n",
    "            z = layer.inverse(z)\n",
    "        return z\n",
    "\n",
    "# Define a function to train the Real NVP model for 2D data\n",
    "def train_real_nvp_2d(model, data, n_epochs=100, lr=1e-3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        z, log_det_jacobian = model(data)\n",
    "        # Negative log likelihood loss\n",
    "        loss = -torch.mean(torch.sum(torch.distributions.Normal(0, 1).log_prob(z), dim=1) + log_det_jacobian)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{n_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c63f7-12cf-4046-9921-9494ec42a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Real NVP Implementation for Image Data ###\n",
    "class AffineCouplingLayer(nn.Module):\n",
    "    def __init__(self, num_channels, hidden_channels, mask):\n",
    "        super(AffineCouplingLayer, self).__init__()\n",
    "        self.mask = mask # The mask indicates which vector values are translated\n",
    "        self.scale_net = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, hidden_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, num_channels, kernel_size=3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.translate_net = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, hidden_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, num_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = self.mask.to(x.device)  # Ensure the mask is on the same device as x\n",
    "        x1 = x * mask\n",
    "        s = self.scale_net(x1) * (1 - mask) #sigma Network in the slides\n",
    "        t = self.translate_net(x1) * (1 - mask) #mu Network in the slides\n",
    "        z = x1 + (1 - mask) * (x * torch.exp(s) + t) \n",
    "        log_det_jacobian = torch.sum((1 - mask) * s, dim=[1, 2, 3])\n",
    "        return z, log_det_jacobian\n",
    "\n",
    "    def inverse(self, z):\n",
    "        mask = self.mask.to(z.device)  # Ensure the mask is on the same device as z\n",
    "        z1 = z * mask\n",
    "        s = self.scale_net(z1) * (1 - mask)\n",
    "        t = self.translate_net(z1) * (1 - mask)\n",
    "        x = z1 + (1 - mask) * (z - t) * torch.exp(-s)\n",
    "        return x\n",
    "\n",
    "# Define the Real NVP Model for images with the updated AffineCouplingLayer\n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, num_channels, hidden_channels, num_coupling_layers):\n",
    "        super(RealNVP, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_coupling_layers = num_coupling_layers\n",
    "\n",
    "        self.masks = []\n",
    "        for i in range(num_coupling_layers):\n",
    "            mask = torch.zeros(1, num_channels, 32, 32)\n",
    "            mask[:, :, i % 2::2, :] = 1  # We are going to use Checkerboard mask for images\n",
    "            self.masks.append(mask)\n",
    "\n",
    "        self.coupling_layers = nn.ModuleList([AffineCouplingLayer(num_channels, hidden_channels, self.masks[i])\n",
    "                                              for i in range(num_coupling_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        log_det_jacobian = 0\n",
    "        for layer in self.coupling_layers:\n",
    "            x, layer_log_det_jacobian = layer(x)\n",
    "            log_det_jacobian += layer_log_det_jacobian\n",
    "        return x, log_det_jacobian\n",
    "\n",
    "    def inverse(self, z):\n",
    "        for layer in reversed(self.coupling_layers):\n",
    "            z = layer.inverse(z)\n",
    "        return z\n",
    "\n",
    "# Define a function to train the Real NVP model on CIFAR-10\n",
    "def train_real_nvp(model, train_loader, n_epochs=10, lr=1e-4):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, _ in train_loader:\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            z, log_det_jacobian = model(x)\n",
    "            # Compute the loss as the negative log likelihood\n",
    "            log_prob_z = torch.sum(torch.distributions.Normal(0, 1).log_prob(z), dim=[1, 2, 3])\n",
    "            loss = -torch.mean(log_prob_z + log_det_jacobian)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{n_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5ebc7-f14c-4c8b-8993-adece717857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train FFJORD on 2D data\n",
    "def train_ffjord_2d(model, data, n_epochs=100, lr=1e-3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    integration_times = torch.tensor([0.0, 1.0]).to(data.device)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        z = model(data, integration_times)[1]\n",
    "        # Negative log likelihood loss\n",
    "        log_prob_z = torch.sum(torch.distributions.Normal(0, 1).log_prob(z), dim=1)\n",
    "        loss = -torch.mean(log_prob_z)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{n_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Train FFJORD on Gaussian mixture\n",
    "class ODEFunc2D(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ODEFunc2D, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        return self.net(y)\n",
    "\n",
    "class FFJORD2D(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FFJORD2D, self).__init__()\n",
    "        self.ode_func = ODEFunc2D(input_dim)\n",
    "\n",
    "    def forward(self, x, integration_times):\n",
    "        return odeint(self.ode_func, x, integration_times)\n",
    "\n",
    "\n",
    "\n",
    "### FFJORD Implementation for images ###\n",
    "class ODEFuncImage(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ODEFuncImage, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(input_dim, 64, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(64, input_dim, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        return self.net(y)\n",
    "\n",
    "class FFJORDImage(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(FFJORDImage, self).__init__()\n",
    "        self.ode_func = ODEFuncImage(num_channels)\n",
    "\n",
    "    def forward(self, x, integration_times):\n",
    "        return odeint(self.ode_func, x, integration_times)\n",
    "\n",
    "# Define a function to train FFJORD on CIFAR-10\n",
    "def train_ffjord_images(model, train_loader, n_epochs=10, lr=1e-4):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    integration_times = torch.tensor([0.0, 1.0]).to(device)  # ODE integration from 0 to 1\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, _ in train_loader:\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x, integration_times)[1]\n",
    "            # Compute the loss as the negative log likelihood\n",
    "            log_prob_z = torch.sum(torch.distributions.Normal(0, 1).log_prob(z), dim=[1, 2, 3])\n",
    "            loss = -torch.mean(log_prob_z)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{n_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3fce64-e0ca-4bc8-9cb1-3ca62e28cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf65d3d-3d6f-4cee-b912-c44700d1ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize Gaussian mixture data\n",
    "n_samples = 5000\n",
    "n_components = 5\n",
    "dim = 2\n",
    "data, _ = generate_mixture_of_gaussians(n_samples, n_components, dim)\n",
    "data = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "\n",
    "plot_data(data.cpu().numpy(), 'Original Mixture of Gaussians')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f82e51e-54a5-463d-a600-b5fd5396c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Real NVP on Gaussian mixture\n",
    "print(\"Training Real NVP on Gaussian Mixture Data...\")\n",
    "real_nvp_2d = RealNVP2D(dim, 128, 6).to(device)\n",
    "start_time = time.time()\n",
    "train_real_nvp_2d(real_nvp_2d, data, n_epochs=100, lr=1e-5)\n",
    "end_time = time.time()\n",
    "print(f\"Real NVP Training Time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "z_nvp_2d, _ = real_nvp_2d(data)\n",
    "plot_data(z_nvp_2d.cpu().detach().numpy(), 'Transformed Data (Real NVP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c344b-3fc0-4550-97ec-9f4d5c0f1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training FFJORD on Gaussian Mixture Data...\")\n",
    "ffjord_2d = FFJORD2D(dim).to(device)\n",
    "start_time = time.time()\n",
    "train_ffjord_2d(ffjord_2d, data, n_epochs=100, lr=1e-3)\n",
    "end_time = time.time()\n",
    "print(f\"FFJORD Training Time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "integration_times = torch.tensor([0.0, 1.0]).to(device)\n",
    "z_ffjord_2d = ffjord_2d(data, integration_times)[1]\n",
    "plot_data(z_ffjord_2d.cpu().detach().numpy(), 'Transformed Data (FFJORD)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2a07a-76a1-4012-95fd-78f76951460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Real NVP and FFJORD for CIFAR-10 Images ###\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "num_channels = 3  # CIFAR-10 has 3 color channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb3bbe-0ead-4f00-a631-e40b04262c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train Real NVP for images\n",
    "print(\"Training Real NVP on CIFAR-10 Data...\")\n",
    "real_nvp_model_image = RealNVP(num_channels, 64, 8).to(device)\n",
    "start_time = time.time()\n",
    "train_real_nvp(real_nvp_model_image, train_loader, n_epochs=10, lr=1e-4)\n",
    "end_time = time.time()\n",
    "print(f\"Real NVP (Image) Training Time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5bcebd-92bc-4713-a94c-5c9f58e5c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and visualize transformations\n",
    "real_nvp_model_image.eval()\n",
    "test_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "with torch.no_grad():\n",
    "    x, _ = next(iter(test_loader))\n",
    "    x = x.to(device)\n",
    "    z_nvp_image, _ = real_nvp_model_image(x)\n",
    "    x_reconstructed_nvp = real_nvp_model_image.inverse(z_nvp_image).cpu().numpy()\n",
    "\n",
    "plot_images_grid(x.cpu().numpy(), 'Original CIFAR-10 Images (Real NVP)')\n",
    "plot_images_grid(x_reconstructed_nvp, 'Reconstructed CIFAR-10 Images (Real NVP)')\n",
    "# Free memory\n",
    "del real_nvp_model_image\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76abc052-2e31-4ea4-a343-181709aeb64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a7721-070c-4c95-ba03-dd35f98c9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train FFJORD for images\n",
    "print(\"Training FFJORD on CIFAR-10 Data...\")\n",
    "ffjord_model_image = FFJORDImage(num_channels).to(device)\n",
    "start_time = time.time()\n",
    "train_ffjord_images(ffjord_model_image, train_loader, n_epochs=10, lr=1e-4)\n",
    "end_time = time.time()\n",
    "print(f\"FFJORD (Image) Training Time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb773829-2dee-48bf-8cd6-3920280b969f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c2db7-f25a-41b9-abec-fdb542f4a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and visualize transformations\n",
    "ffjord_model_image.eval()\n",
    "with torch.no_grad():\n",
    "    z_ffjord_image = ffjord_model_image(x, integration_times)[1]\n",
    "\n",
    "plot_images_grid(x.cpu().numpy(), 'Original CIFAR-10 Images (FFJORD)')\n",
    "plot_images_grid(z_ffjord_image.cpu().numpy(), 'Transformed CIFAR-10 Images (FFJORD)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
